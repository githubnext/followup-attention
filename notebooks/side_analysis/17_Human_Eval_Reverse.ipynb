{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal**: use the data in the Human eval in the reverse direction to predict the next assert (aka test) given the correct function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import project_path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from termcolor import colored\n",
    "import re\n",
    "import pathlib\n",
    "from typing import List, Tuple, Dict, Any, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from human_eval.data import write_jsonl, read_problems\n",
    "\n",
    "problems = read_problems()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_FOLDER = \"../data/prompts_collection/reverse_human_eval\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task id: HumanEval/0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['task_id', 'prompt', 'entry_point', 'canonical_solution', 'test'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_id = list(problems.keys())[0]\n",
    "print(\"task id:\", task_id)\n",
    "c_problem = problems[task_id]\n",
    "c_problem.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from typing import List\n",
      "\n",
      "\n",
      "def has_close_elements(numbers: List[float], threshold: float) -> bool:\n",
      "    \"\"\" Check if in given list of numbers, are any two numbers closer to each other than\n",
      "    given threshold.\n",
      "    >>> has_close_elements([1.0, 2.0, 3.0], 0.5)\n",
      "    False\n",
      "    >>> has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\n",
      "    True\n",
      "    \"\"\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(c_problem[\"prompt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    for idx, elem in enumerate(numbers):\n",
      "        for idx2, elem2 in enumerate(numbers):\n",
      "            if idx != idx2:\n",
      "                distance = abs(elem - elem2)\n",
      "                if distance < threshold:\n",
      "                    return True\n",
      "\n",
      "    return False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(c_problem[\"canonical_solution\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "METADATA = {\n",
      "    'author': 'jt',\n",
      "    'dataset': 'test'\n",
      "}\n",
      "\n",
      "\n",
      "def check(candidate):\n",
      "    assert candidate([1.0, 2.0, 3.9, 4.0, 5.0, 2.2], 0.3) == True\n",
      "    assert candidate([1.0, 2.0, 3.9, 4.0, 5.0, 2.2], 0.05) == False\n",
      "    assert candidate([1.0, 2.0, 5.9, 4.0, 5.0], 0.95) == True\n",
      "    assert candidate([1.0, 2.0, 5.9, 4.0, 5.0], 0.8) == False\n",
      "    assert candidate([1.0, 2.0, 3.0, 4.0, 5.0, 2.0], 0.1) == True\n",
      "    assert candidate([1.1, 2.2, 3.1, 4.1, 5.1], 1.0) == True\n",
      "    assert candidate([1.1, 2.2, 3.1, 4.1, 5.1], 0.5) == False\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(c_problem[\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a new prompt dataset\n",
    "\n",
    "**Input prompt**:\n",
    "1. function (without doctests)\n",
    "2. assert function_name(...\n",
    "\n",
    "**Expected Output**: \n",
    "1. completion of the test (HUMAN and MACHINE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def vowels_count(s):\n",
      "    \"\"\"Write a function vowels_count which takes a string representing\n",
      "    a word as input and returns the number of vowels in the string.\n",
      "    Vowels in this case are 'a', 'e', 'i', 'o', 'u'. Here, 'y' is also a\n",
      "    vowel, but only when it is at the end of the given word.\n",
      "\n",
      "    Example:\n",
      "    >>> vowels_count(\"abcde\")\n",
      "    2\n",
      "    >>> vowels_count(\"ACEDY\")\n",
      "    3\n",
      "    \"\"\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def remove_doctests(text: str) -> str:\n",
    "    \"\"\"Remove all the text after the first occurrence of `>>>`.\"\"\"\n",
    "    docstring_opening_sequence = \"'''\" if \"'''\" in text else '\"\"\"'\n",
    "    if \">>>\" in text:\n",
    "        return text[:text.index(\">>>\")] + docstring_opening_sequence + '\\n'\n",
    "    return text\n",
    "\n",
    "def remove_examples(text: str) -> str:\n",
    "    \"\"\"Remove all the examples in the code.\"\"\"\n",
    "    docstring_opening_sequence = \"'''\" if \"'''\" in text else '\"\"\"'\n",
    "    first_line_with_example = None\n",
    "\n",
    "    if \"example\" in text.lower():\n",
    "        lines = text.split(\"\\n\")\n",
    "        for i, line in enumerate(lines):\n",
    "            if \"example\" in line.lower():\n",
    "                first_line_with_example = i\n",
    "                break\n",
    "    if first_line_with_example is None:\n",
    "        return text\n",
    "    lines = text.split(\"\\n\")\n",
    "    return \"\\n\".join(lines[:first_line_with_example]) + f'\\n    {docstring_opening_sequence}\\n'\n",
    "\n",
    "def remove_example_of_api_usage(text: str) -> str:\n",
    "    \"\"\"Remove the example of API usage from the docstring.\n",
    "    \n",
    "    Note that this includes examples which are not in the form or doctest, \n",
    "    neither prefaced by 'example' string.\n",
    "    \"\"\"\n",
    "    docstring_opening_sequence = \"'''\" if \"'''\" in text else '\"\"\"'\n",
    "    function_name = get_function_name(text)\n",
    "    lines = text.split(\"\\n\")\n",
    "    consider_this_line_for_removal = False\n",
    "    new_lines = []\n",
    "    for i, line in enumerate(lines):\n",
    "        # consider only examples in the docstring\n",
    "        if docstring_opening_sequence in line:\n",
    "            consider_this_line_for_removal = True\n",
    "        \n",
    "        # the example should have the opened bracket\n",
    "        if consider_this_line_for_removal:\n",
    "            if not f\"{function_name}(\" in line.lower():\n",
    "                new_lines.append(line)\n",
    "        else:\n",
    "            new_lines.append(line)\n",
    "    return \"\\n\".join(new_lines)\n",
    "\n",
    "def remove_evety_thing_before_def(text: str) -> str:\n",
    "    \"\"\"Remove everything before the first occurrence of `def`.\"\"\"\n",
    "    lines = text.split(\"\\n\")\n",
    "    for i, line in enumerate(lines):\n",
    "        if line.strip().startswith(\"def\"):\n",
    "            return \"\\n\".join(lines[i:])\n",
    "\n",
    "def get_function_name(function_text: str) -> str: \n",
    "    \"\"\"Extract the function name from the function text.\"\"\"\n",
    "    match = re.search(r\"def ([^\\(]+)\", function_text)\n",
    "    if not match:\n",
    "        raise ValueError(f\"Could not find function name in: {function_text}\")\n",
    "    return match.group(1)\n",
    "\n",
    "#print(remove_examples(problems[\"HumanEval/163\"][\"prompt\"]))\n",
    "\n",
    "\n",
    "print(remove_evety_thing_before_def(problems[\"HumanEval/64\"][\"prompt\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "task id: HumanEval/0\n",
      "INPUT: To the model: \n",
      "\u001b[34mdef has_close_elements(numbers: List[float], threshold: float) -> bool:\n",
      "    \"\"\" Check if in given list of numbers, are any two numbers closer to each other than\n",
      "    given threshold.\n",
      "    \"\"\"\n",
      "    for idx, elem in enumerate(numbers):\n",
      "        for idx2, elem2 in enumerate(numbers):\n",
      "            if idx != idx2:\n",
      "                distance = abs(elem - elem2)\n",
      "                if distance < threshold:\n",
      "                    return True\n",
      "\n",
      "    return False\n",
      "\n",
      "# Write a test for the function has_close_elements below\n",
      "assert has_close_elements(\u001b[0m\n",
      "OUTPUT: From the model: \n",
      "\u001b[35m\n",
      "\n",
      "METADATA = {\n",
      "    'author': 'jt',\n",
      "    'dataset': 'test'\n",
      "}\n",
      "\n",
      "\n",
      "def check(candidate):\n",
      "    assert candidate([1.0, 2.0, 3.9, 4.0, 5.0, 2.2], 0.3) == True\n",
      "    assert candidate([1.0, 2.0, 3.9, 4.0, 5.0, 2.2], 0.05) == False\n",
      "    assert candidate([1.0, 2.0, 5.9, 4.0, 5.0], 0.95) == True\n",
      "    assert candidate([1.0, 2.0, 5.9, 4.0, 5.0], 0.8) == False\n",
      "    assert candidate([1.0, 2.0, 3.0, 4.0, 5.0, 2.0], 0.1) == True\n",
      "    assert candidate([1.1, 2.2, 3.1, 4.1, 5.1], 1.0) == True\n",
      "    assert candidate([1.1, 2.2, 3.1, 4.1, 5.1], 0.5) == False\n",
      "\n",
      "\u001b[0m\n",
      "================================================================================\n",
      "task id: HumanEval/1\n",
      "INPUT: To the model: \n",
      "\u001b[34mdef separate_paren_groups(paren_string: str) -> List[str]:\n",
      "    \"\"\" Input to this function is a string containing multiple groups of nested parentheses. Your goal is to\n",
      "    separate those group into separate strings and return the list of those.\n",
      "    Separate groups are balanced (each open brace is properly closed) and not nested within each other\n",
      "    Ignore any spaces in the input string.\n",
      "    \"\"\"\n",
      "    result = []\n",
      "    current_string = []\n",
      "    current_depth = 0\n",
      "\n",
      "    for c in paren_string:\n",
      "        if c == '(':\n",
      "            current_depth += 1\n",
      "            current_string.append(c)\n",
      "        elif c == ')':\n",
      "            current_depth -= 1\n",
      "            current_string.append(c)\n",
      "\n",
      "            if current_depth == 0:\n",
      "                result.append(''.join(current_string))\n",
      "                current_string.clear()\n",
      "\n",
      "    return result\n",
      "\n",
      "# Write a test for the function separate_paren_groups below\n",
      "assert separate_paren_groups(\u001b[0m\n",
      "OUTPUT: From the model: \n",
      "\u001b[35m\n",
      "\n",
      "METADATA = {\n",
      "    'author': 'jt',\n",
      "    'dataset': 'test'\n",
      "}\n",
      "\n",
      "\n",
      "def check(candidate):\n",
      "    assert candidate('(()()) ((())) () ((())()())') == [\n",
      "        '(()())', '((()))', '()', '((())()())'\n",
      "    ]\n",
      "    assert candidate('() (()) ((())) (((())))') == [\n",
      "        '()', '(())', '((()))', '(((())))'\n",
      "    ]\n",
      "    assert candidate('(()(())((())))') == [\n",
      "        '(()(())((())))'\n",
      "    ]\n",
      "    assert candidate('( ) (( )) (( )( ))') == ['()', '(())', '(()())']\n",
      "\u001b[0m\n",
      "================================================================================\n",
      "task id: HumanEval/2\n",
      "INPUT: To the model: \n",
      "\u001b[34mdef truncate_number(number: float) -> float:\n",
      "    \"\"\" Given a positive floating point number, it can be decomposed into\n",
      "    and integer part (largest integer smaller than given number) and decimals\n",
      "    (leftover part always smaller than 1).\n",
      "\n",
      "    Return the decimal part of the number.\n",
      "    \"\"\"\n",
      "    return number % 1.0\n",
      "\n",
      "# Write a test for the function truncate_number below\n",
      "assert truncate_number(\u001b[0m\n",
      "OUTPUT: From the model: \n",
      "\u001b[35m\n",
      "\n",
      "METADATA = {\n",
      "    'author': 'jt',\n",
      "    'dataset': 'test'\n",
      "}\n",
      "\n",
      "\n",
      "def check(candidate):\n",
      "    assert candidate(3.5) == 0.5\n",
      "    assert abs(candidate(1.33) - 0.33) < 1e-6\n",
      "    assert abs(candidate(123.456) - 0.456) < 1e-6\n",
      "\u001b[0m\n",
      "================================================================================\n",
      "task id: HumanEval/3\n",
      "================================================================================\n",
      "task id: HumanEval/4\n",
      "================================================================================\n",
      "task id: HumanEval/5\n",
      "================================================================================\n",
      "task id: HumanEval/6\n",
      "================================================================================\n",
      "task id: HumanEval/7\n",
      "================================================================================\n",
      "task id: HumanEval/8\n",
      "================================================================================\n",
      "task id: HumanEval/9\n",
      "================================================================================\n",
      "task id: HumanEval/10\n",
      "================================================================================\n",
      "task id: HumanEval/11\n",
      "================================================================================\n",
      "task id: HumanEval/12\n",
      "================================================================================\n",
      "task id: HumanEval/13\n",
      "================================================================================\n",
      "task id: HumanEval/14\n",
      "================================================================================\n",
      "task id: HumanEval/15\n",
      "================================================================================\n",
      "task id: HumanEval/16\n",
      "================================================================================\n",
      "task id: HumanEval/17\n",
      "================================================================================\n",
      "task id: HumanEval/18\n",
      "================================================================================\n",
      "task id: HumanEval/19\n",
      "================================================================================\n",
      "task id: HumanEval/20\n",
      "================================================================================\n",
      "task id: HumanEval/21\n",
      "================================================================================\n",
      "task id: HumanEval/22\n",
      "================================================================================\n",
      "task id: HumanEval/23\n",
      "================================================================================\n",
      "task id: HumanEval/24\n",
      "================================================================================\n",
      "task id: HumanEval/25\n",
      "================================================================================\n",
      "task id: HumanEval/26\n",
      "================================================================================\n",
      "task id: HumanEval/27\n",
      "================================================================================\n",
      "task id: HumanEval/28\n",
      "================================================================================\n",
      "task id: HumanEval/29\n",
      "================================================================================\n",
      "task id: HumanEval/30\n",
      "================================================================================\n",
      "task id: HumanEval/31\n",
      "================================================================================\n",
      "task id: HumanEval/32\n",
      "================================================================================\n",
      "task id: HumanEval/33\n",
      "================================================================================\n",
      "task id: HumanEval/34\n",
      "================================================================================\n",
      "task id: HumanEval/35\n",
      "================================================================================\n",
      "task id: HumanEval/36\n",
      "================================================================================\n",
      "task id: HumanEval/37\n",
      "================================================================================\n",
      "task id: HumanEval/38\n",
      "================================================================================\n",
      "task id: HumanEval/39\n",
      "================================================================================\n",
      "task id: HumanEval/40\n",
      "================================================================================\n",
      "task id: HumanEval/41\n",
      "================================================================================\n",
      "task id: HumanEval/42\n",
      "================================================================================\n",
      "task id: HumanEval/43\n",
      "================================================================================\n",
      "task id: HumanEval/44\n",
      "================================================================================\n",
      "task id: HumanEval/45\n",
      "================================================================================\n",
      "task id: HumanEval/46\n",
      "================================================================================\n",
      "task id: HumanEval/47\n",
      "================================================================================\n",
      "task id: HumanEval/48\n",
      "================================================================================\n",
      "task id: HumanEval/49\n",
      "================================================================================\n",
      "task id: HumanEval/50\n",
      "================================================================================\n",
      "task id: HumanEval/51\n",
      "================================================================================\n",
      "task id: HumanEval/52\n",
      "================================================================================\n",
      "task id: HumanEval/53\n",
      "================================================================================\n",
      "task id: HumanEval/54\n",
      "================================================================================\n",
      "task id: HumanEval/55\n",
      "================================================================================\n",
      "task id: HumanEval/56\n",
      "================================================================================\n",
      "task id: HumanEval/57\n",
      "================================================================================\n",
      "task id: HumanEval/58\n",
      "================================================================================\n",
      "task id: HumanEval/59\n",
      "================================================================================\n",
      "task id: HumanEval/60\n",
      "================================================================================\n",
      "task id: HumanEval/61\n",
      "================================================================================\n",
      "task id: HumanEval/62\n",
      "================================================================================\n",
      "task id: HumanEval/63\n",
      "================================================================================\n",
      "task id: HumanEval/64\n",
      "================================================================================\n",
      "task id: HumanEval/65\n",
      "================================================================================\n",
      "task id: HumanEval/66\n",
      "================================================================================\n",
      "task id: HumanEval/67\n",
      "================================================================================\n",
      "task id: HumanEval/68\n",
      "================================================================================\n",
      "task id: HumanEval/69\n",
      "================================================================================\n",
      "task id: HumanEval/70\n",
      "================================================================================\n",
      "task id: HumanEval/71\n",
      "================================================================================\n",
      "task id: HumanEval/72\n",
      "================================================================================\n",
      "task id: HumanEval/73\n",
      "================================================================================\n",
      "task id: HumanEval/74\n",
      "================================================================================\n",
      "task id: HumanEval/75\n",
      "================================================================================\n",
      "task id: HumanEval/76\n",
      "================================================================================\n",
      "task id: HumanEval/77\n",
      "================================================================================\n",
      "task id: HumanEval/78\n",
      "================================================================================\n",
      "task id: HumanEval/79\n",
      "================================================================================\n",
      "task id: HumanEval/80\n",
      "================================================================================\n",
      "task id: HumanEval/81\n",
      "================================================================================\n",
      "task id: HumanEval/82\n",
      "================================================================================\n",
      "task id: HumanEval/83\n",
      "================================================================================\n",
      "task id: HumanEval/84\n",
      "================================================================================\n",
      "task id: HumanEval/85\n",
      "================================================================================\n",
      "task id: HumanEval/86\n",
      "================================================================================\n",
      "task id: HumanEval/87\n",
      "================================================================================\n",
      "task id: HumanEval/88\n",
      "================================================================================\n",
      "task id: HumanEval/89\n",
      "================================================================================\n",
      "task id: HumanEval/90\n",
      "================================================================================\n",
      "task id: HumanEval/91\n",
      "================================================================================\n",
      "task id: HumanEval/92\n",
      "================================================================================\n",
      "task id: HumanEval/93\n",
      "================================================================================\n",
      "task id: HumanEval/94\n",
      "================================================================================\n",
      "task id: HumanEval/95\n",
      "================================================================================\n",
      "task id: HumanEval/96\n",
      "================================================================================\n",
      "task id: HumanEval/97\n",
      "================================================================================\n",
      "task id: HumanEval/98\n",
      "================================================================================\n",
      "task id: HumanEval/99\n",
      "================================================================================\n",
      "task id: HumanEval/100\n",
      "================================================================================\n",
      "task id: HumanEval/101\n",
      "================================================================================\n",
      "task id: HumanEval/102\n",
      "================================================================================\n",
      "task id: HumanEval/103\n",
      "================================================================================\n",
      "task id: HumanEval/104\n",
      "================================================================================\n",
      "task id: HumanEval/105\n",
      "================================================================================\n",
      "task id: HumanEval/106\n",
      "================================================================================\n",
      "task id: HumanEval/107\n",
      "================================================================================\n",
      "task id: HumanEval/108\n",
      "================================================================================\n",
      "task id: HumanEval/109\n",
      "================================================================================\n",
      "task id: HumanEval/110\n",
      "================================================================================\n",
      "task id: HumanEval/111\n",
      "================================================================================\n",
      "task id: HumanEval/112\n",
      "================================================================================\n",
      "task id: HumanEval/113\n",
      "================================================================================\n",
      "task id: HumanEval/114\n",
      "================================================================================\n",
      "task id: HumanEval/115\n",
      "================================================================================\n",
      "task id: HumanEval/116\n",
      "================================================================================\n",
      "task id: HumanEval/117\n",
      "================================================================================\n",
      "task id: HumanEval/118\n",
      "================================================================================\n",
      "task id: HumanEval/119\n",
      "================================================================================\n",
      "task id: HumanEval/120\n",
      "================================================================================\n",
      "task id: HumanEval/121\n",
      "================================================================================\n",
      "task id: HumanEval/122\n",
      "================================================================================\n",
      "task id: HumanEval/123\n",
      "================================================================================\n",
      "task id: HumanEval/124\n",
      "================================================================================\n",
      "task id: HumanEval/125\n",
      "================================================================================\n",
      "task id: HumanEval/126\n",
      "================================================================================\n",
      "task id: HumanEval/127\n",
      "================================================================================\n",
      "task id: HumanEval/128\n",
      "================================================================================\n",
      "task id: HumanEval/129\n",
      "================================================================================\n",
      "task id: HumanEval/130\n",
      "================================================================================\n",
      "task id: HumanEval/131\n",
      "================================================================================\n",
      "task id: HumanEval/132\n",
      "================================================================================\n",
      "task id: HumanEval/133\n",
      "================================================================================\n",
      "task id: HumanEval/134\n",
      "================================================================================\n",
      "task id: HumanEval/135\n",
      "================================================================================\n",
      "task id: HumanEval/136\n",
      "================================================================================\n",
      "task id: HumanEval/137\n",
      "================================================================================\n",
      "task id: HumanEval/138\n",
      "================================================================================\n",
      "task id: HumanEval/139\n",
      "================================================================================\n",
      "task id: HumanEval/140\n",
      "================================================================================\n",
      "task id: HumanEval/141\n",
      "================================================================================\n",
      "task id: HumanEval/142\n",
      "================================================================================\n",
      "task id: HumanEval/143\n",
      "================================================================================\n",
      "task id: HumanEval/144\n",
      "================================================================================\n",
      "task id: HumanEval/145\n",
      "================================================================================\n",
      "task id: HumanEval/146\n",
      "================================================================================\n",
      "task id: HumanEval/147\n",
      "================================================================================\n",
      "task id: HumanEval/148\n",
      "================================================================================\n",
      "task id: HumanEval/149\n",
      "================================================================================\n",
      "task id: HumanEval/150\n",
      "================================================================================\n",
      "task id: HumanEval/151\n",
      "================================================================================\n",
      "task id: HumanEval/152\n",
      "================================================================================\n",
      "task id: HumanEval/153\n",
      "================================================================================\n",
      "task id: HumanEval/154\n",
      "================================================================================\n",
      "task id: HumanEval/155\n",
      "================================================================================\n",
      "task id: HumanEval/156\n",
      "================================================================================\n",
      "task id: HumanEval/157\n",
      "================================================================================\n",
      "task id: HumanEval/158\n",
      "================================================================================\n",
      "task id: HumanEval/159\n",
      "================================================================================\n",
      "task id: HumanEval/160\n",
      "================================================================================\n",
      "task id: HumanEval/161\n",
      "================================================================================\n",
      "task id: HumanEval/162\n",
      "================================================================================\n",
      "task id: HumanEval/163\n"
     ]
    }
   ],
   "source": [
    "COMPLETION_HOOK = \"\\n# Write a test for the function [[FUNCTION_NAME]] below\\nassert [[FUNCTION_NAME]](\"\n",
    "INPSECT_FIRST = 3\n",
    "\n",
    "# create output folder if it does not exist\n",
    "if not os.path.exists(OUTPUT_FOLDER):\n",
    "    pathlib.Path(OUTPUT_FOLDER).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# for each problem \n",
    "for i, task_id in enumerate(list(problems.keys())):\n",
    "    #if i < INPSECT_FIRST:\n",
    "    print(\"=\" * 80)\n",
    "    print(\"task id:\", task_id)\n",
    "    c_problem = problems[task_id]\n",
    "    clean_prompt = \\\n",
    "        remove_example_of_api_usage(\n",
    "            remove_examples(\n",
    "                remove_doctests(\n",
    "                    remove_evety_thing_before_def(\n",
    "                        c_problem[\"prompt\"]))))\n",
    "    canonical_solution = c_problem[\"canonical_solution\"]\n",
    "    function_name = get_function_name(clean_prompt)\n",
    "    completion_hook = COMPLETION_HOOK.replace(\"[[FUNCTION_NAME]]\", function_name)\n",
    "\n",
    "\n",
    "    reverse_task_prompt = clean_prompt + canonical_solution + completion_hook\n",
    "\n",
    "    if i < INPSECT_FIRST:\n",
    "        print(\"INPUT: To the model: \")\n",
    "        print(colored(reverse_task_prompt, 'blue'))\n",
    "        print(\"OUTPUT: From the model: \")\n",
    "        print(colored(c_problem[\"test\"], 'magenta'))\n",
    "\n",
    "\n",
    "    # save the output\n",
    "    escaped_task_id = task_id.replace(\"/\", \"_\")\n",
    "    output_file = os.path.join(\n",
    "        OUTPUT_FOLDER, f\"{escaped_task_id}_{function_name}.py\")\n",
    "    with open(output_file, \"w\") as f:\n",
    "        f.write(reverse_task_prompt)\n",
    "    output_reference_file = os.path.join(\n",
    "        OUTPUT_FOLDER, f\"{escaped_task_id}_{function_name}.ref\")\n",
    "    with open(output_reference_file, \"w\") as f:\n",
    "        f.write(c_problem[\"test\"])\n",
    "    # save the original prompt\n",
    "    output_original_prompt_file = os.path.join(\n",
    "        OUTPUT_FOLDER, f\"{escaped_task_id}_{function_name}.original\")\n",
    "    with open(output_original_prompt_file, \"w\") as f:\n",
    "        f.write(c_problem[\"prompt\"] + c_problem[\"canonical_solution\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need for a sandbox to run the tests."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cdbdd4cf7f5282af921e9e9f8e89536c1a615a288e4742df81a89abd7b1a94fe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
